{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Tutorial5",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "toc-autonumbering": true
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/german1728/Chimera/blob/master/Copia_de_Tutorial5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPrix6kifJzt"
      },
      "source": [
        "# Tutorial 5\n",
        "# Selección de modelo: compensación de sesgo-varianza\n",
        "\n",
        "**Content creators**: Pierre-Étienne Fiquet, Anqi Wu, Alex Hyafil with help from Ella Batty\n",
        "\n",
        "**Content reviewers**: Lina Teichmann, Patrick Mineault, Michael Waskom\n",
        "\n",
        "**Content traductor**: Israel Chaparro\n",
        "\n",
        "**Source**: Neuromatch Academy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlpjiOgfJzv"
      },
      "source": [
        "---\n",
        "#Objetivos del tutorial\n",
        "\n",
        "Este es el Tutorial 5 de una serie sobre cómo ajustar modelos a datos. Comenzamos con regresión lineal simple, usando optimización de mínimos cuadrados (Tutorial 1) y Estimación de máxima verosimilitud (Tutorial 2). Usaremos bootstrapping para construir intervalos de confianza alrededor de los parámetros del modelo lineal inferido (Tutorial 3). Terminaremos nuestra exploración de modelos de regresión generalizando a la regresión lineal múltiple y la regresión polinomial (Tutorial 4). Terminamos aprendiendo a elegir entre estos distintos modelos. Analizamos la compensación de sesgo-varianza (Tutorial 5) y la Validación cruzada para la selección del modelo (Tutorial 6).\n",
        "\n",
        "En este tutorial, aprenderemos sobre la compensación de sesgo-varianza y la veremos en acción usando modelos de regresión polinomial.\n",
        "\n",
        "Objetivos del tutorial:\n",
        "\n",
        "* Comprender la diferencia entre la prueba y los datos del tren.\n",
        "* Compare el tren y el error de prueba para modelos de diversa complejidad\n",
        "* Comprender cómo se relaciona el equilibrio entre sesgo y varianza con el modelo que elegimos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ_DNFj9fJz2"
      },
      "source": [
        "---\n",
        "# Configuracion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "q-nLdEpafJz3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_61scl_fJz7"
      },
      "source": [
        "#@title Configuracion de Figuras\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UTVPrx9fJ0A"
      },
      "source": [
        "#@title Funciones de Ayuda\n",
        "def ordinary_least_squares(x, y):\n",
        "  \"\"\"Ordinary least squares estimator for linear regression.\n",
        "\n",
        "  Args:\n",
        "    x (ndarray): design matrix of shape (n_samples, n_regressors)\n",
        "    y (ndarray): vector of measurements of shape (n_samples)\n",
        "\n",
        "  Returns:\n",
        "    ndarray: estimated parameter values of shape (n_regressors)\n",
        "  \"\"\"\n",
        "\n",
        "  return np.linalg.inv(x.T @ x) @ x.T @ y\n",
        "\n",
        "def make_design_matrix(x, order):\n",
        "  \"\"\"Create the design matrix of inputs for use in polynomial regression\n",
        "\n",
        "  Args:\n",
        "    x (ndarray): input vector of shape (n_samples)\n",
        "    order (scalar): polynomial regression order\n",
        "\n",
        "  Returns:\n",
        "    ndarray: design matrix for polynomial regression of shape (samples, order+1)\n",
        "  \"\"\"\n",
        "\n",
        "  # Broadcast to shape (n x 1) so dimensions work\n",
        "  if x.ndim == 1:\n",
        "    x = x[:, None]\n",
        "\n",
        "  #if x has more than one feature, we don't want multiple columns of ones so we assign\n",
        "  # x^0 here\n",
        "  design_matrix = np.ones((x.shape[0],1))\n",
        "\n",
        "  # Loop through rest of degrees and stack columns\n",
        "  for degree in range(1, order+1):\n",
        "      design_matrix = np.hstack((design_matrix, x**degree))\n",
        "\n",
        "  return design_matrix\n",
        "\n",
        "\n",
        "def solve_poly_reg(x, y, max_order):\n",
        "  \"\"\"Fit a polynomial regression model for each order 0 through max_order.\n",
        "\n",
        "  Args:\n",
        "    x (ndarray): input vector of shape (n_samples)\n",
        "    y (ndarray): vector of measurements of shape (n_samples)\n",
        "    max_order (scalar): max order for polynomial fits\n",
        "\n",
        "  Returns:\n",
        "    dict: fitted weights for each polynomial model (dict key is order)\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary with polynomial order as keys, and np array of theta\n",
        "  # (weights) as the values\n",
        "  theta_hats = {}\n",
        "\n",
        "  # Loop over polynomial orders from 0 through max_order\n",
        "  for order in range(max_order+1):\n",
        "\n",
        "    X = make_design_matrix(x, order)\n",
        "    this_theta = ordinary_least_squares(X, y)\n",
        "\n",
        "    theta_hats[order] = this_theta\n",
        "\n",
        "  return theta_hats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpfN13mWfJ0F"
      },
      "source": [
        "---\n",
        "# Sección 1: Datos de prueba vs tren\n",
        "\n",
        "Los datos utilizados para el procedimiento de ajuste para un modelo dado son los **datos de entrenamiento**. En el tutorial 4, calculamos MSE sobre los datos de entrenamiento de nuestros modelos de regresión polinomial y comparamos el MSE de entrenamiento entre modelos. Un tipo de datos adicional importante son **datos de prueba**. Estos son datos retenidos que no se utilizan (de ninguna manera) durante el procedimiento de ajuste. Al ajustar modelos, a menudo queremos considerar tanto el error del tren (la calidad de la predicción en los datos de entrenamiento) como el error de la prueba (la calidad de la predicción en los datos de la prueba), como veremos en la siguiente sección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A7bUhVyfJ0G"
      },
      "source": [
        "Generaremos algunos datos ruidosos para usar en este tutorial usando un proceso similar al del Tutorial 4, sin embargo, ahora también generaremos datos de prueba. Queremos ver cómo nuestro modelo se generaliza más allá del rango de valores que vemos en la fase de entrenamiento. Para lograr esto, generaremos x a partir de un rango más amplio de valores ([-3, 3]). Luego trazamos el tren y los datos de prueba juntos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naVLQKvxfJ0H"
      },
      "source": [
        "#@title\n",
        "#@markdown Ejecute esta celda para simular tanto los datos de entrenamiento como los de prueba\n",
        "\n",
        "### Generate training data\n",
        "np.random.seed(0)\n",
        "n_train_samples = 50\n",
        "x_train = np.random.uniform(-2, 2.5, n_train_samples) # sample from a uniform distribution over [-2, 2.5)\n",
        "noise = np.random.randn(n_train_samples) # sample from a standard normal distribution\n",
        "y_train =  x_train**2 - x_train - 2 + noise\n",
        "\n",
        "### Generate testing data\n",
        "n_test_samples = 20\n",
        "x_test = np.random.uniform(-3, 3, n_test_samples) # sample from a uniform distribution over [-2, 2.5)\n",
        "noise = np.random.randn(n_test_samples) # sample from a standard normal distribution\n",
        "y_test =  x_test**2 - x_test - 2 + noise\n",
        "\n",
        "## Plot both train and test data\n",
        "fig, ax = plt.subplots()\n",
        "plt.title('Training & Test Data')\n",
        "plt.plot(x_train, y_train, '.', markersize=15, label='Training')\n",
        "plt.plot(x_test, y_test, 'g+', markersize=15, label='Test')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCs3Y05fJ0M"
      },
      "source": [
        "---\n",
        "# Sección 2: Compensación de sesgo-varianza\n",
        "\n",
        "Encontrar un buen modelo puede resultar complicado. Uno de los conceptos más importantes a tener en cuenta al modelar es la **compensación entre sesgo y varianza**.\n",
        "\n",
        "**Sesgo** es la diferencia entre la predicción del modelo y las correspondientes variables de salida verdaderas que está intentando predecir. Los modelos con alto sesgo no se ajustarán bien a los datos de entrenamiento ya que las predicciones son bastante diferentes de los datos reales. Estos modelos de alto sesgo están demasiado simplificados: no tienen suficientes parámetros y complejidad para capturar con precisión los patrones en los datos y, por lo tanto, **no se ajustan correctamente**.\n",
        "\n",
        "\n",
        "**Varianza** se refiere a la variabilidad de las predicciones del modelo para una entrada determinada. Esencialmente, ¿las predicciones del modelo cambian mucho con los cambios en los datos de entrenamiento exactos utilizados? Los modelos con una alta varianza dependen en gran medida de los datos de entrenamiento exactos utilizados; no se generalizarán bien para probar los datos. Estos modelos de alta varianza están **sobreajustados** a los datos.\n",
        "\n",
        "En esencia:\n",
        "\n",
        "* Los modelos de alto sesgo y baja varianza tienen un alto error de tren y de prueba.\n",
        "* Bajo sesgo, los modelos de alta varianza tienen un error de tren bajo, error de prueba alto\n",
        "* Los modelos de bajo sesgo y baja varianza tienen un tren y un error de prueba bajos\n",
        "\n",
        "Como podemos ver en esta lista, ¡idealmente queremos modelos de bajo sesgo y baja varianza! Sin embargo, estos objetivos pueden entrar en conflicto: los modelos con la complejidad suficiente para tener un sesgo bajo también tienden a sobreajustarse y dependen más de los datos de entrenamiento. Necesitamos decidir cuál es la compensación correcta.\n",
        "\n",
        "En esta sección, veremos la compensación de sesgo-varianza en acción con modelos de regresión polinomial de diferentes órdenes.\n",
        "\n",
        "Ilustración gráfica de sesgo y varianza.\n",
        "(Fuente: http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
        "\n",
        "![sesgo-varianza](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/images/bias_variance/bullseye.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPpWIMbTfJ0P"
      },
      "source": [
        "Primero ajustaremos modelos de regresión polinomial de órdenes 0-5 en nuestros datos de entrenamiento simulados tal como hicimos en el Tutorial 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvVE5UCCfJ0Q"
      },
      "source": [
        "#@title\n",
        "#@markdown Ejecute esta celda para estimar theta_hats\n",
        "max_order = 5\n",
        "theta_hats = solve_poly_reg(x_train, y_train, max_order)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbfVTIC8fJ0V"
      },
      "source": [
        "### Ejercicio 1: Calcule y compare el error del tren con el de la prueba\n",
        "\n",
        "Usaremos MSE como nuestra métrica de error nuevamente. Calcule MSE en datos de entrenamiento ($ x_{train}, y_{train} $) y datos de prueba ($ x_{test}, y_{test} $) para cada modelo de regresión polinomial (órdenes 0-5). Dado que ya desarrolló código en el Ejercicio 4 de T4 para evaluar polinomios de ajuste, lo hemos trasladado aquí a la función ``eval_poly_reg`` para su uso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdbjLflzfJ0W"
      },
      "source": [
        "def evaluate_poly_reg(x, y, theta_hats, max_order):\n",
        "    \"\"\" Evaluates MSE of polynomial regression models on data\n",
        "\n",
        "    Args:\n",
        "      x (ndarray): input vector of shape (n_samples)\n",
        "      y (ndarray): vector of measurements of shape (n_samples)\n",
        "      theta_hats (dict):  fitted weights for each polynomial model (dict key is order)\n",
        "      max_order (scalar): max order of polynomial fit\n",
        "\n",
        "    Returns\n",
        "      (ndarray): mean squared error for each order, shape (max_order)\n",
        "    \"\"\"\n",
        "\n",
        "    mse = np.zeros((max_order + 1))\n",
        "    for order in range(0, max_order + 1):\n",
        "      X_design = make_design_matrix(x, order)\n",
        "      y_hat = np.dot(X_design, theta_hats[order])\n",
        "      residuals = y - y_hat\n",
        "      mse[order] = np.mean(residuals ** 2)\n",
        "\n",
        "    return mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WbhjS0fJ0a"
      },
      "source": [
        "def compute_mse(x_train,x_test,y_train,y_test,theta_hats,max_order):\n",
        "  \"\"\"Compute MSE on training data and test data.\n",
        "\n",
        "  Args:\n",
        "    x_train(ndarray): training data input vector of shape (n_samples)\n",
        "    x_test(ndarray): test data input vector of shape (n_samples)\n",
        "    y_train(ndarray): training vector of measurements of shape (n_samples)\n",
        "    y_test(ndarray): test vector of measurements of shape (n_samples)\n",
        "    theta_hats(dict): fitted weights for each polynomial model (dict key is order)\n",
        "    max_order (scalar): max order of polynomial fit\n",
        "\n",
        "  Returns:\n",
        "    ndarray, ndarray: MSE error on training data and test data for each order\n",
        "  \"\"\"\n",
        "\n",
        "  mse_train = ...\n",
        "  mse_test = ...\n",
        "\n",
        "  return mse_train, mse_test\n",
        "\n",
        "\n",
        "#Descomente a continuación para probar su función\n",
        "# mse_train, mse_test = compute_mse(x_train, x_test, y_train, y_test, theta_hats, max_order)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "width = .35\n",
        "\n",
        "# ax.bar(np.arange(max_order + 1) - width / 2, mse_train, width, label=\"train MSE\")\n",
        "# ax.bar(np.arange(max_order + 1) + width / 2, mse_test , width, label=\"test MSE\")\n",
        "\n",
        "ax.legend()\n",
        "ax.set(xlabel='Polynomial order', ylabel='MSE', title ='Comparing polynomial fits');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellView": "both",
        "outputId": "959f79ef-68d2-474d-9e3e-0666a9f8e83e",
        "id": "9OmrcxWmfJ0e"
      },
      "source": [
        "[*Haga clic para obtener una solución*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D3_ModelFitting/solutions/W1D3_Tutorial5_Solution_b3fdca6e.py)\n",
        "\n",
        "*Salida de ejemplo:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=558 height=414 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D3_ModelFitting/static/W1D3_Tutorial5_Solution_b3fdca6e_0.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dg2bsTwfJ0f"
      },
      "source": [
        "Como podemos ver en el gráfico anterior, los modelos más complejos (polinomios de orden superior) tienen un MSE más bajo para los datos de entrenamiento. Los modelos demasiado simplificados (órdenes 0 y 1) tienen un alto MSE en los datos de entrenamiento. A medida que agregamos complejidad al modelo, pasamos de un sesgo alto a un sesgo bajo.\n",
        "\n",
        "El MSE de los datos de prueba sigue un patrón diferente. El mejor MSE de prueba es para un modelo de orden 2; esto tiene sentido ya que los datos se generaron con un modelo de orden 2. Tanto los modelos más simples como los modelos más complejos tienen un MSE de prueba más alto.\n",
        "\n",
        "Entonces, para recapitular:\n",
        "\n",
        "Modelo de orden 0: alto sesgo, baja varianza\n",
        "\n",
        "Modelo de orden 5: sesgo bajo, alta varianza\n",
        "\n",
        "Modelo de orden 2: justo, bajo sesgo, baja varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHuape3nfJ0g"
      },
      "source": [
        "---\n",
        "# Resumen\n",
        "\n",
        "- Los datos de entrenamiento son los datos utilizados para el ajuste, los datos de prueba son datos retenidos.\n",
        "- Necesitamos encontrar el equilibrio adecuado entre sesgo y varianza. Idealmente, queremos encontrar un modelo con una complejidad de modelo óptima que tenga tanto sesgo bajo como varianza baja\n",
        "  - Los modelos demasiado complejos tienen un sesgo bajo y una gran varianza.\n",
        "  - Los modelos demasiado simples tienen un sesgo alto y una varianza baja."
      ]
    }
  ]
}