{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "Tutorial3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/german1728/Chimera/blob/master/Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVTb4qkXfHre"
      },
      "source": [
        "# Tutorial 3\n",
        "# Ajuste del modelo: intervalos de confianza y bootstrapping\n",
        "\n",
        "**Content creators**: Pierre-Étienne Fiquet, Anqi Wu, Alex Hyafil with help from Byron Galbraith\n",
        "\n",
        "**Content reviewers**: Lina Teichmann, Saeed Salehi, Patrick Mineault, Ella Batty, Michael Waskom \n",
        "\n",
        "**Content traduction**: Israel Chaparro\n",
        "\n",
        "Source: Neuromatch Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzNcdA8dfHrf"
      },
      "source": [
        "#Objetivos del tutorial\n",
        "\n",
        "Este es el Tutorial 3 de una serie sobre cómo ajustar modelos a datos. Comenzamos con regresión lineal simple, usando optimización de mínimos cuadrados (Tutorial 1) y Estimación de máxima verosimilitud (Tutorial 2). Usaremos bootstrapping para construir intervalos de confianza alrededor de los parámetros del modelo lineal inferido (Tutorial 3). Terminaremos nuestra exploración de modelos de regresión generalizando a la regresión lineal múltiple y la regresión polinomial (Tutorial 4). Terminamos aprendiendo a elegir entre estos distintos modelos. Analizamos la compensación de sesgo-varianza (Tutorial 5) y la Validación cruzada para la selección del modelo (Tutorial 6).\n",
        "\n",
        "En este tutorial, discutiremos cómo medir qué tan buenos son nuestros parámetros estimados del modelo.\n",
        "- Aprenda a usar bootstrapping para generar nuevos conjuntos de datos de muestra\n",
        "- Estime el parámetro de nuestro modelo en estos nuevos conjuntos de datos de muestra.\n",
        "- Cuantificar la varianza de nuestra estimación utilizando intervalos de confianza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6bCYoWhfHrm"
      },
      "source": [
        "Hasta este punto, hemos estado encontrando formas de estimar los parámetros del modelo para ajustar algunos datos observados. Nuestro enfoque ha sido optimizar algún criterio, ya sea minimizar el error cuadrático medio o maximizar la probabilidad al usar el conjunto de datos completo. ¿Qué tan buena es realmente nuestra estimación? ¿Qué tan seguros estamos de que se generalizará para describir nuevos datos que aún no hemos visto?\n",
        "\n",
        "Una solución a esto es simplemente recopilar más datos y verificar el MSE en este nuevo conjunto de datos con los parámetros estimados previamente. Sin embargo, esto no siempre es factible y aún deja abierta la cuestión de cuán cuantificablemente confiados estamos en la precisión de nuestro modelo.\n",
        "\n",
        "En la Sección 1, exploraremos cómo implementar bootstrapping. En la Sección 2, crearemos intervalos de confianza de nuestras estimaciones utilizando el método de arranque."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB62dPBQfHrn"
      },
      "source": [
        "---\n",
        "# Configuraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "dHSQL8iLfHrn"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlDGf4QnfHrt"
      },
      "source": [
        "#@title Configuraciones de Figuras\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oekoj1gqfHrx"
      },
      "source": [
        "#@title Funciones de ayuda\n",
        "def solve_normal_eqn(x, y):\n",
        "  \"\"\"Solve the normal equations to produce the value of theta_hat that minimizes\n",
        "    MSE.\n",
        "\n",
        "    Args:\n",
        "    x (ndarray): An array of shape (samples,) that contains the input values.\n",
        "    y (ndarray): An array of shape (samples,) that contains the corresponding\n",
        "      measurement values to the inputs.\n",
        "    thata_hat (float): An estimate of the slope parameter.\n",
        "\n",
        "  Returns:\n",
        "    float: the value for theta_hat arrived from minimizing MSE\n",
        "  \"\"\"\n",
        "  theta_hat = (x.T @ y) / (x.T @ x)\n",
        "  return theta_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVD-ILGPfHr2"
      },
      "source": [
        "---\n",
        "# Sección 1: Bootstrapping\n",
        "\n",
        "Bootstrapping es un método ampliamente aplicable para evaluar la confianza/incertidumbre acerca de los parámetros estimados, originalmente fue propuesto por Bradley Efron. La idea es generar muchos conjuntos de datos sintéticos nuevos a partir del conjunto de datos verdadero inicial mediante un muestreo aleatorio de él, luego encontrar estimadores para cada uno de estos nuevos conjuntos de datos y, finalmente, observar la distribución de todos estos estimadores para cuantificar nuestra confianza.\n",
        "\n",
        "Tenga en cuenta que cada nuevo conjunto de datos remuestreado tendrá el mismo tamaño que el original, con los nuevos puntos de datos muestreados con reemplazo, es decir, podemos repetir el mismo punto de datos varias veces. También tenga en cuenta que en la práctica necesitamos muchos conjuntos de datos remuestreados, aquí usamos 2000.\n",
        "\n",
        "Para explorar esta idea, comenzaremos nuevamente con nuestras muestras ruidosas a lo largo de la línea $ y_n = 1.2x_n + \\epsilon_n $, pero esta vez solo usaremos la mitad de los puntos de datos como la última vez (15 en lugar de 30)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56KKhk-fHr3"
      },
      "source": [
        "#@title\n",
        "\n",
        "#@markdown Ejecuta esta celda para simular algo de data\n",
        "\n",
        "# setting a fixed seed to our random number generator ensures we will always\n",
        "# get the same psuedorandom number sequence\n",
        "np.random.seed(121)\n",
        "\n",
        "# Let's set some parameters\n",
        "theta = 1.2\n",
        "n_samples = 15\n",
        "\n",
        "# Draw x and then calculate y\n",
        "x = 10 * np.random.rand(n_samples)  # sample from a uniform distribution over [0,10)\n",
        "noise = np.random.randn(n_samples)  # sample from a standard normal distribution\n",
        "y = theta * x + noise\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x, y)  # produces a scatter plot\n",
        "ax.set(xlabel='x', ylabel='y');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzquGPbnfHr7"
      },
      "source": [
        "### Ejercicio 1: Volver a muestrear el conjunto de datos con reemplazo\n",
        "\n",
        "En este ejercicio, implementará un método para volver a muestrear un conjunto de datos con reemplazo. El método acepta matrices $ x $ y $ y $. Debería devolver un nuevo conjunto de matrices $ x'$ y $ y' $ que se crean mediante un muestreo aleatorio de los originales.\n",
        "\n",
        "Luego compararemos el conjunto de datos original con un conjunto de datos remuestreado.\n",
        "\n",
        "TIP: La función [numpy.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) sería útil aquí."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "lxU-40dPfHr9"
      },
      "source": [
        "def resample_with_replacement(x, y):\n",
        "  \"\"\"Resample data points with replacement from the dataset of `x` inputs and\n",
        "  `y` measurements.\n",
        "\n",
        "  Args:\n",
        "    x (ndarray): An array of shape (samples,) that contains the input values.\n",
        "    y (ndarray): An array of shape (samples,) that contains the corresponding\n",
        "      measurement values to the inputs.\n",
        "\n",
        "  Returns:\n",
        "    ndarray, ndarray: The newly resampled `x` and `y` data points.\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtenga una variedad de índices para puntos remuestreados\n",
        "  sample_idx = ...\n",
        "\n",
        "  # Muestra de x e y de acuerdo con sample_idx\n",
        "  x_ = ...\n",
        "  y_ = ...\n",
        "  return x_, y_\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "ax1.scatter(x, y)\n",
        "ax1.set(title='Original', xlabel='x', ylabel='y')\n",
        "\n",
        "# Descomente a continuación para probar su función\n",
        "#x_, y_ = resample_with_replacement(x, y)\n",
        "#ax2.scatter(x_, y_, color='c')\n",
        "\n",
        "ax2.set(title='Remuestreado', xlabel='x', ylabel='y',\n",
        "        xlim=ax1.get_xlim(), ylim=ax1.get_ylim());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellView": "both",
        "outputId": "5a909627-719a-414c-f7cc-f8ca724e50ec",
        "id": "1N5faDijfHsC"
      },
      "source": [
        "[*Haga clic para obtener una solución*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D3_ModelFitting/solutions/W1D3_Tutorial3_Solution_fe37e229.py)\n",
        "\n",
        "*Salida de ejemplo:*\n",
        "\n",
        "<img alt='Sugerencia de solución' align='left' width=845 height=341 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D3_ModelFitting/static/W1D3_Tutorial3_Solution_fe37e229_0.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAqdG_0LfHsD"
      },
      "source": [
        "En la gráfica remuestreada de la derecha, el número real de puntos es el mismo, pero algunos se han repetido, por lo que solo se muestran una vez.\n",
        "\n",
        "Ahora que tenemos una forma de volver a muestrear los datos, podemos usarla en el proceso de arranque completo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhKmgyAyfHsE"
      },
      "source": [
        "### Ejercicio 2: Estimaciones de Bootstrap\n",
        "\n",
        "En este ejercicio, implementará un método para ejecutar el proceso de arranque de generar un conjunto de valores $ \\hat\\theta $ a partir de un conjunto de datos de entradas $ x $ y medidas $ y $. Debe usar `resample_with_replacement` aquí, y también puede invocar la función auxiliar `solve_normal_eqn` del Tutorial 1 para producir el estimador basado en MSE.\n",
        "\n",
        "Luego usaremos esta función para ver theta_hat de diferentes muestras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCZkKJBofHsE"
      },
      "source": [
        "def bootstrap_estimates(x, y, n=2000):\n",
        "  \"\"\"Generate a set of theta_hat estimates using the bootstrap method.\n",
        "\n",
        "  Args:\n",
        "    x (ndarray): An array of shape (samples,) that contains the input values.\n",
        "    y (ndarray): An array of shape (samples,) that contains the corresponding\n",
        "      measurement values to the inputs.\n",
        "    n (int): The number of estimates to compute\n",
        "\n",
        "  Returns:\n",
        "    ndarray: An array of estimated parameters with size (n,)\n",
        "  \"\"\"\n",
        "  theta_hats = np.zeros(n)\n",
        "\n",
        "  # Bucle sobre el número de estimaciones\n",
        "  for i in range(n):\n",
        "\n",
        "    # Remuestrear x e y\n",
        "    x_, y_ = ...\n",
        "\n",
        "    # Calcule theta_hat para esta muestra\n",
        "    theta_hats[i] = ...\n",
        "\n",
        "  return theta_hats\n",
        "\n",
        "\n",
        "np.random.seed(123)  # establecer semilla aleatoria para comprobar soluciones\n",
        "\n",
        "# Descomente a continuación para probar la función\n",
        "# theta_hats = bootstrap_estimates(x, y, n=2000)\n",
        "# print(theta_hats[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellView": "both",
        "outputId": "62745943-e46a-4a1e-b67f-e6fa30fbcbd7",
        "id": "JZg8DnGffHsI"
      },
      "source": [
        "[*Haga clic para obtener una solución*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D3_ModelFitting/solutions/W1D3_Tutorial3_Solution_315a8d02.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmR44eyWfHsJ"
      },
      "source": [
        "Deberías ver `[1.27550888 1.17317819 1.18198819 1.25329255 1.20714664]` como las cinco primeras estimaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip8RDQJIfHsK"
      },
      "source": [
        "Ahora que tenemos nuestras estimaciones de arranque, podemos visualizar todos los modelos potenciales (modelos calculados con diferentes remuestreos) juntos para ver qué tan distribuidos están."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASs-q5LcfHsL"
      },
      "source": [
        "#@title\n",
        "#@markdown Ejecute esta celda para visualizar todos los modelos potenciales\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# For each theta_hat, plot model\n",
        "theta_hats = bootstrap_estimates(x, y, n=2000)\n",
        "for i, theta_hat in enumerate(theta_hats):\n",
        "  y_hat = theta_hat * x\n",
        "  ax.plot(x, y_hat, c='r', alpha=0.01, label='Resampled Fits' if i==0 else '')\n",
        "\n",
        "# Plot observed data\n",
        "ax.scatter(x, y, label='Observed')\n",
        "\n",
        "# Plot true fit data\n",
        "y_true = theta * x\n",
        "ax.plot(x, y_true, 'g', linewidth=2, label='True Model')\n",
        "\n",
        "ax.set(\n",
        "  title='Bootstrapped Slope Estimation',\n",
        "  xlabel='x',\n",
        "  ylabel='y'\n",
        ")\n",
        "\n",
        "# Change legend line alpha property\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "handles[0].set_alpha(1)\n",
        "\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BGpnO1cfHsP"
      },
      "source": [
        "¡Esto se ve bastante bien! Las estimaciones de bootstrap se extienden alrededor del modelo real, como hubiéramos esperado. Tenga en cuenta que aquí tenemos el lujo de conocer el valor real básico de $ \\ theta $, pero en las aplicaciones estamos tratando de adivinarlo a partir de los datos. Por lo tanto, evaluar la calidad de las estimaciones basadas en datos finitos es una tarea de fundamental importancia en el análisis de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kJT6hHDfHsQ"
      },
      "source": [
        "---\n",
        "# Sección 2: Intervalos de confianza\n",
        "\n",
        "Cuantifiquemos ahora qué tan incierta es nuestra pendiente estimada. Lo hacemos calculando intervalos de confianza (CIs) a partir de nuestras estimaciones de arranque. El enfoque más directo es calcular percentiles a partir de la distribución empírica de estimaciones bootstrap. Tenga en cuenta que esto es ampliamente aplicable ya que no estamos asumiendo que esta distribución empírica sea gaussiana."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7GnX85mfHsQ"
      },
      "source": [
        "#@title\n",
        "\n",
        "#@markdown Ejecute esta celda para trazar Intervalos de Confianza de arranque\n",
        "\n",
        "theta_hats = bootstrap_estimates(x, y, n=2000)\n",
        "print(f\"mean = {np.mean(theta_hats):.2f}, std = {np.std(theta_hats):.2f}\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(theta_hats, bins=20, facecolor='C1', alpha=0.75)\n",
        "ax.axvline(theta, c='g', label=r'True $\\theta$')\n",
        "ax.axvline(np.percentile(theta_hats, 50), color='r', label='Median')\n",
        "ax.axvline(np.percentile(theta_hats, 2.5), color='b', label='95% CI')\n",
        "ax.axvline(np.percentile(theta_hats, 97.5), color='b')\n",
        "ax.legend()\n",
        "ax.set(\n",
        "    title='Bootstrapped Confidence Interval',\n",
        "    xlabel=r'$\\hat{{\\theta}}$',\n",
        "    ylabel='count',\n",
        "    xlim=[1.0, 1.5]\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auNI5PYwfHsV"
      },
      "source": [
        "Al observar la distribución de los valores de $ \\hat{\\theta} $ bootstrap, vemos que el verdadero $ \\theta $ cae dentro del intervalo de confianza del 95%, lo que es reasegurador. También vemos que el valor $ \\theta = 1 $ no cae dentro del intervalo de confianza. A partir de esto, rechazaríamos la hipótesis de que la pendiente fuera 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz0oxYCTfHsV"
      },
      "source": [
        "---\n",
        "# Resumen\n",
        "\n",
        "- Bootstrapping es un procedimiento de remuestreo que permite construir intervalos de confianza alrededor de valores de parámetros inferidos\n",
        "- es un método ampliamente aplicable y muy práctico que se basa en el poder computacional y generadores de números pseudoaleatorios (a diferencia de los enfoques más clásicos que dependen de derivaciones analíticas)"
      ]
    }
  ]
}